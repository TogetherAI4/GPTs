## Introduction

](/docs/api-reference/introduction)

You can interact with the API through HTTP requests from any language, via our official Python bindings, our official Node.js library, or a [community-maintained library](/docs/libraries/community-libraries).

To install the official Python bindings, run the following command:

    pip install openai

To install the official Node.js library, run the following command in your Node.js project directory:

    npm install openai@^4.0.0

[

## Authentication

](/docs/api-reference/authentication)

The OpenAI API uses API keys for authentication. Visit your [API Keys](/account/api-keys) page to retrieve the API key you'll use in your requests.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

All API requests should include your API key in an `Authorization` HTTP header as follows:

    Authorization: Bearer OPENAI_API_KEY

[

### Organization (optional)

](/docs/api-reference/organization-optional)

For users who belong to multiple organizations, you can pass a header to specify which organization is used for an API request. Usage from these API requests will count as usage for the specified organization.

Example curl command:

    1
    2
    3
    curl https://api.openai.com/v1/models \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "OpenAI-Organization: org-Y5wey0kEQEFH5MtsjR7Hs3RT"

Example with the `openai` Python package:

    1
    2
    3
    4
    5
    from openai import OpenAI

    client = OpenAI(
      organization='org-Y5wey0kEQEFH5MtsjR7Hs3RT',
    )

Example with the `openai` Node.js package:

    1
    2
    3
    4
    5
    import OpenAI from "openai";

    const openai = new OpenAI({
      organization: 'org-Y5wey0kEQEFH5MtsjR7Hs3RT',
    });

Organization IDs can be found on your [Organization settings](/account/organization) page.

[

## Making requests

](/docs/api-reference/making-requests)

You can paste the command below into your terminal to run your first API request. Make sure to replace `$OPENAI_API_KEY` with your secret API key.

    1
    2
    3
    4
    5
    6
    7
    8
    curl https://api.openai.com/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
         "model": "gpt-3.5-turbo",
         "messages": [{"role": "user", "content": "Say this is a test!"}],
         "temperature": 0.7
       }'

This request queries the `gpt-3.5-turbo` model (which under the hood points to a [`gpt-3.5-turbo` model variant](/docs/models/gpt-3-5-turbo)) to complete the text starting with a prompt of "_Say this is a test_". You should get a response back that resembles the following:

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    {
        "id": "chatcmpl-abc123",
        "object": "chat.completion",
        "created": 1677858242,
        "model": "gpt-3.5-turbo-0613",
        "usage": {
            "prompt_tokens": 13,
            "completion_tokens": 7,
            "total_tokens": 20
        },
        "choices": [
            {
                "message": {
                    "role": "assistant",
                    "content": "\n\nThis is a test!"
                },
                "logprobs": null,
                "finish_reason": "stop",
                "index": 0
            }
        ]
    }

Now that you've generated your first chat completion, let's break down the [response object](/docs/api-reference/chat/object). We can see the `finish_reason` is `stop` which means the API returned the full chat completion generated by the model without running into any limits. In the choices list, we only generated a single message but you can set the `n` parameter to generate multiple messages choices.

[

## Streaming

](/docs/api-reference/streaming)

The OpenAI API provides the ability to stream responses back to a client in order to allow partial results for certain requests. To achieve this, we follow the [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) standard.

Our official [Node](https://github.com/openai/openai-node) and [Python](https://github.com/openai/openai-python) libraries handle Server-sent events for you. In Python, a streaming request looks like:

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    from openai import OpenAI

    client = OpenAI()

    stream = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": "Say this is a test"}],
        stream=True,
    )
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="")

In Node / Typescript, a streaming request looks like:

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    import OpenAI from "openai";

    const openai = new OpenAI();

    async function main() {
        const stream = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [{ role: "user", content: "Say this is a test" }],
            stream: true,
        });
        for await (const chunk of stream) {
            process.stdout.write(chunk.choices[0]?.delta?.content || "");
        }
    }

    main();

[

#### Parsing Server-sent events

](/docs/api-reference/parsing-server-sent-events)

Parsing Server-sent events is non-trivial and should be done with caution. Simple strategies like splitting by a new line may result in parsing errors. We recommend using [existing client libraries](/docs/libraries) when possible.

[

## Audio

](/docs/api-reference/audio)

Learn how to turn audio into text or text into audio.

Related guide: [Speech to text](/docs/guides/speech-to-text)

[

## Create speech

](/docs/api-reference/audio/createSpeech)

post <https://api.openai.com/v1/audio/speech>

Generates audio from the input text.

### Request body

[](#audio-createspeech-model)

model

string

Required

One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`

[](#audio-createspeech-input)

input

string

Required

The text to generate audio for. The maximum length is 4096 characters.

[](#audio-createspeech-voice)

voice

string

Required

The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech/voice-options).

[](#audio-createspeech-response_format)

response_format

string

Optional

Defaults to mp3

The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`.

[](#audio-createspeech-speed)

speed

number

Optional

Defaults to 1

The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.

### Returns

The audio file content.

Example request

python

Select library curl python node

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    from pathlib import Path
    import openai

    speech_file_path = Path(__file__).parent / "speech.mp3"
    response = openai.audio.speech.create(
      model="tts-1",
      voice="alloy",
      input="The quick brown fox jumped over the lazy dog."
    )
    response.stream_to_file(speech_file_path)

[

## Create transcription

](/docs/api-reference/audio/createTranscription)

post <https://api.openai.com/v1/audio/transcriptions>

Transcribes audio into the input language.

### Request body

[](#audio-createtranscription-file)

file

file

Required

The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

[](#audio-createtranscription-model)

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

[](#audio-createtranscription-language)

language

string

Optional

The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

[](#audio-createtranscription-prompt)

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.

[](#audio-createtranscription-response_format)

response_format

string

Optional

Defaults to json

The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

[](#audio-createtranscription-temperature)

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

[](#audio-createtranscription-timestamp_granularities)

timestamp_granularities\[\]

array

Optional

Defaults to segment

The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

### Returns

The [transcription object](/docs/api-reference/audio/json-object) or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).

Default‍ Word timestamps‍ Segment timestamps‍

Example request

python

Select library curl python node

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    audio_file = open("speech.mp3", "rb")
    transcript = client.audio.transcriptions.create(
      model="whisper-1",
      file=audio_file
    )

Response

Copy‍

    1
    2
    3
    {
      "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }

[

## Create translation

](/docs/api-reference/audio/createTranslation)

post <https://api.openai.com/v1/audio/translations>

Translates audio into English.

### Request body

[](#audio-createtranslation-file)

file

file

Required

The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

[](#audio-createtranslation-model)

model

string

Required

ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.

[](#audio-createtranslation-prompt)

prompt

string

Optional

An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.

[](#audio-createtranslation-response_format)

response_format

string

Optional

Defaults to json

The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.

[](#audio-createtranslation-temperature)

temperature

number

Optional

Defaults to 0

The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

### Returns

The translated text.

Example request

python

Select library curl python node

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    audio_file = open("speech.mp3", "rb")
    transcript = client.audio.translations.create(
      model="whisper-1",
      file=audio_file
    )

Response

Copy‍

    1
    2
    3
    {
      "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
    }

[

## The transcription object

](/docs/api-reference/audio/json-object)

Represents a transcription response returned by model, based on the provided input.

[](#audio/json-object-text)

text

string

The transcribed text.

The transcription object

Copy‍

    1
    2
    3
    {
      "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }

[

## The transcription object

](/docs/api-reference/audio/verbose-json-object)

Represents a verbose json transcription response returned by model, based on the provided input.

[](#audio/verbose-json-object-language)

language

string

The language of the input audio.

[](#audio/verbose-json-object-duration)

duration

string

The duration of the input audio.

[](#audio/verbose-json-object-text)

text

string

The transcribed text.

[](#audio/verbose-json-object-words)

words

array

Extracted words and their corresponding timestamps.

Hide properties

[](#audio/verbose-json-object-words-word)

word

string

The text content of the word.

[](#audio/verbose-json-object-words-start)

start

number

Start time of the word in seconds.

[](#audio/verbose-json-object-words-end)

end

number

End time of the word in seconds.

[](#audio/verbose-json-object-segments)

segments

array

Segments of the transcribed text and their corresponding details.

Hide properties

[](#audio/verbose-json-object-segments-id)

id

integer

Unique identifier of the segment.

[](#audio/verbose-json-object-segments-seek)

seek

integer

Seek offset of the segment.

[](#audio/verbose-json-object-segments-start)

start

number

Start time of the segment in seconds.

[](#audio/verbose-json-object-segments-end)

end

number

End time of the segment in seconds.

[](#audio/verbose-json-object-segments-text)

text

string

Text content of the segment.

[](#audio/verbose-json-object-segments-tokens)

tokens

array

Array of token IDs for the text content.

[](#audio/verbose-json-object-segments-temperature)

temperature

number

Temperature parameter used for generating the segment.

[](#audio/verbose-json-object-segments-avg_logprob)

avg_logprob

number

Average logprob of the segment. If the value is lower than -1, consider the logprobs failed.

[](#audio/verbose-json-object-segments-compression_ratio)

compression_ratio

number

Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed.

[](#audio/verbose-json-object-segments-no_speech_prob)

no_speech_prob

number

Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent.

The transcription object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    {
      "task": "transcribe",
      "language": "english",
      "duration": 8.470000267028809,
      "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.319999933242798,
          "text": " The beach was a popular spot on a hot summer day.",
          "tokens": [
            50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2860786020755768,
          "compression_ratio": 1.2363636493682861,
          "no_speech_prob": 0.00985979475080967
        },
        ...
      ]
    }

[

## Chat

](/docs/api-reference/chat)

Given a list of messages comprising a conversation, the model will return a response.

Related guide: [Chat Completions](/docs/guides/text-generation)

[

## Create chat completion

](/docs/api-reference/chat/create)

post <https://api.openai.com/v1/chat/completions>

Creates a model response for the given chat conversation.

### Request body

[](#chat-create-messages)

messages

array

Required

A list of messages comprising the conversation so far. [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).

Hide possible types

System message

object

Hide properties

[](#chat-create-messages-system-message-content)

content

string

Required

The contents of the system message.

[](#chat-create-messages-system-message-role)

role

string

Required

The role of the messages author, in this case `system`.

[](#chat-create-messages-system-message-name)

name

string

Optional

An optional name for the participant. Provides the model information to differentiate between participants of the same role.

User message

object

Hide properties

[](#chat-create-messages-user-message-content)

content

string or array

Required

The contents of the user message.

Hide possible types

Text content

string

The text contents of the message.

Array of content parts

array

An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. Image input is only supported when using the `gpt-4-visual-preview` model.

Hide possible types

Text content part

object

Hide properties

[](#chat-create-messages-user-message-content-array-of-content-parts-text-content-part-type)

type

string

Required

The type of the content part.

[](#chat-create-messages-user-message-content-array-of-content-parts-text-content-part-text)

text

string

Required

The text content.

Image content part

object

Hide properties

[](#chat-create-messages-user-message-content-array-of-content-parts-image-content-part-type)

type

string

Required

The type of the content part.

[](#chat-create-messages-user-message-content-array-of-content-parts-image-content-part-image_url)

image_url

object

Required

Hide properties

[](#chat-create-messages-user-message-content-array-of-content-parts-image-content-part-image_url-url)

url

string

Required

Either a URL of the image or the base64 encoded image data.

[](#chat-create-messages-user-message-content-array-of-content-parts-image-content-part-image_url-detail)

detail

string

Optional

Defaults to auto

Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding).

[](#chat-create-messages-user-message-role)

role

string

Required

The role of the messages author, in this case `user`.

[](#chat-create-messages-user-message-name)

name

string

Optional

An optional name for the participant. Provides the model information to differentiate between participants of the same role.

Assistant message

object

Hide properties

[](#chat-create-messages-assistant-message-content)

content

string or null

Optional

The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.

[](#chat-create-messages-assistant-message-role)

role

string

Required

The role of the messages author, in this case `assistant`.

[](#chat-create-messages-assistant-message-name)

name

string

Optional

An optional name for the participant. Provides the model information to differentiate between participants of the same role.

[](#chat-create-messages-assistant-message-tool_calls)

tool_calls

array

Optional

The tool calls generated by the model, such as function calls.

Hide properties

[](#chat-create-messages-assistant-message-tool_calls-id)

id

string

Required

The ID of the tool call.

[](#chat-create-messages-assistant-message-tool_calls-type)

type

string

Required

The type of the tool. Currently, only `function` is supported.

[](#chat-create-messages-assistant-message-tool_calls-function)

function

object

Required

The function that the model called.

Hide properties

[](#chat-create-messages-assistant-message-tool_calls-function-name)

name

string

Required

The name of the function to call.

[](#chat-create-messages-assistant-message-tool_calls-function-arguments)

arguments

string

Required

The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.

[](#chat-create-messages-assistant-message-function_call)

function_call

Deprecated

object

Optional

Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.

Hide properties

[](#chat-create-messages-assistant-message-function_call-arguments)

arguments

string

Required

The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.

[](#chat-create-messages-assistant-message-function_call-name)

name

string

Required

The name of the function to call.

Tool message

object

Hide properties

[](#chat-create-messages-tool-message-role)

role

string

Required

The role of the messages author, in this case `tool`.

[](#chat-create-messages-tool-message-content)

content

string

Required

The contents of the tool message.

[](#chat-create-messages-tool-message-tool_call_id)

tool_call_id

string

Required

Tool call that this message is responding to.

Function message

object

Deprecated

Hide properties

[](#chat-create-messages-function-message-role)

role

string

Required

The role of the messages author, in this case `function`.

[](#chat-create-messages-function-message-content)

content

string or null

Required

The contents of the function message.

[](#chat-create-messages-function-message-name)

name

string

Required

The name of the function to call.

[](#chat-create-model)

model

string

Required

ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API.

[](#chat-create-frequency_penalty)

frequency_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

[](#chat-create-logit_bias)

logit_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

[](#chat-create-logprobs)

logprobs

boolean or null

Optional

Defaults to false

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. This option is currently not available on the `gpt-4-vision-preview` model.

[](#chat-create-top_logprobs)

top_logprobs

integer or null

Optional

An integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.

[](#chat-create-max_tokens)

max_tokens

integer or null

Optional

The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.

The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

[](#chat-create-n)

n

integer or null

Optional

Defaults to 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.

[](#chat-create-presence_penalty)

presence_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

[](#chat-create-response_format)

response_format

object

Optional

An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.

Show properties

[](#chat-create-seed)

seed

integer or null

Optional

This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

[](#chat-create-stop)

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens.

[](#chat-create-stream)

stream

boolean or null

Optional

Defaults to false

If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

[](#chat-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

[](#chat-create-top_p)

top_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#chat-create-tools)

tools

array

Optional

A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.

Show properties

[](#chat-create-tool_choice)

tool_choice

string or object

Optional

Controls which (if any) function is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function. Specifying a particular function via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

[](#chat-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

[](#chat-create-function_call)

function_call

Deprecated

string or object

Optional

Deprecated in favor of `tool_choice`.

Controls which (if any) function is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function. Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

`none` is the default when no functions are present. `auto` is the default if functions are present.

Show possible types

[](#chat-create-functions)

functions

Deprecated

array

Optional

Deprecated in favor of `tools`.

A list of functions the model may generate JSON inputs for.

Show properties

### Returns

Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.

Default‍ Image input‍ Streaming‍ Functions‍ Logprobs‍

Example request

gpt-3.5-turbo

gpt-4-turbo-preview gpt-3.5-turbo-0613 gpt-3.5-turbo-0125 gpt-3.5-turbo gpt-3.5-turbo-0301 gpt-3.5-turbo-1106 gpt-3.5-turbo-16k gpt-4 gpt-4-0613 gpt-3.5-turbo-16k-0613 gpt-4-1106-preview gpt-4-0125-preview

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    from openai import OpenAI
    client = OpenAI()

    completion = client.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
      ]
    )

    print(completion.choices[0].message)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    {
      "id": "chatcmpl-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "gpt-3.5-turbo-0125",
      "system_fingerprint": "fp_44709d6fcb",
      "choices": [{
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "\n\nHello there, how may I assist you today?",
        },
        "logprobs": null,
        "finish_reason": "stop"
      }],
      "usage": {
        "prompt_tokens": 9,
        "completion_tokens": 12,
        "total_tokens": 21
      }
    }

[

## The chat completion object

](/docs/api-reference/chat/object)

Represents a chat completion response returned by model, based on the provided input.

[](#chat/object-id)

id

string

A unique identifier for the chat completion.

[](#chat/object-choices)

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Hide properties

[](#chat/object-choices-finish_reason)

finish_reason

string

The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.

[](#chat/object-choices-index)

index

integer

The index of the choice in the list of choices.

[](#chat/object-choices-message)

message

object

A chat completion message generated by the model.

Hide properties

[](#chat/object-choices-message-content)

content

string or null

The contents of the message.

[](#chat/object-choices-message-tool_calls)

tool_calls

array

The tool calls generated by the model, such as function calls.

Hide properties

[](#chat/object-choices-message-tool_calls-id)

id

string

The ID of the tool call.

[](#chat/object-choices-message-tool_calls-type)

type

string

The type of the tool. Currently, only `function` is supported.

[](#chat/object-choices-message-tool_calls-function)

function

object

The function that the model called.

Hide properties

[](#chat/object-choices-message-tool_calls-function-name)

name

string

The name of the function to call.

[](#chat/object-choices-message-tool_calls-function-arguments)

arguments

string

The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.

[](#chat/object-choices-message-role)

role

string

The role of the author of this message.

[](#chat/object-choices-message-function_call)

function_call

Deprecated

object

Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.

Hide properties

[](#chat/object-choices-message-function_call-arguments)

arguments

string

The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.

[](#chat/object-choices-message-function_call-name)

name

string

The name of the function to call.

[](#chat/object-choices-logprobs)

logprobs

object or null

Log probability information for the choice.

Hide properties

[](#chat/object-choices-logprobs-content)

content

array or null

A list of message content tokens with log probability information.

Hide properties

[](#chat/object-choices-logprobs-content-token)

token

string

The token.

[](#chat/object-choices-logprobs-content-logprob)

logprob

number

The log probability of this token.

[](#chat/object-choices-logprobs-content-bytes)

bytes

array or null

A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.

[](#chat/object-choices-logprobs-content-top_logprobs)

top_logprobs

array

List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.

Hide properties

[](#chat/object-choices-logprobs-content-top_logprobs-token)

token

string

The token.

[](#chat/object-choices-logprobs-content-top_logprobs-logprob)

logprob

number

The log probability of this token.

[](#chat/object-choices-logprobs-content-top_logprobs-bytes)

bytes

array or null

A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.

[](#chat/object-created)

created

integer

The Unix timestamp (in seconds) of when the chat completion was created.

[](#chat/object-model)

model

string

The model used for the chat completion.

[](#chat/object-system_fingerprint)

system_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#chat/object-object)

object

string

The object type, which is always `chat.completion`.

[](#chat/object-usage)

usage

object

Usage statistics for the completion request.

Hide properties

[](#chat/object-usage-completion_tokens)

completion_tokens

integer

Number of tokens in the generated completion.

[](#chat/object-usage-prompt_tokens)

prompt_tokens

integer

Number of tokens in the prompt.

[](#chat/object-usage-total_tokens)

total_tokens

integer

Total number of tokens used in the request (prompt + completion).

The chat completion object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    {
      "id": "chatcmpl-123",
      "object": "chat.completion",
      "created": 1677652288,
      "model": "gpt-3.5-turbo-0125",
      "system_fingerprint": "fp_44709d6fcb",
      "choices": [{
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "\n\nHello there, how may I assist you today?",
        },
        "logprobs": null,
        "finish_reason": "stop"
      }],
      "usage": {
        "prompt_tokens": 9,
        "completion_tokens": 12,
        "total_tokens": 21
      }
    }

[

## The chat completion chunk object

](/docs/api-reference/chat/streaming)

Represents a streamed chunk of a chat completion response returned by model, based on the provided input.

[](#chat/streaming-id)

id

string

A unique identifier for the chat completion. Each chunk has the same ID.

[](#chat/streaming-choices)

choices

array

A list of chat completion choices. Can be more than one if `n` is greater than 1.

Hide properties

[](#chat/streaming-choices-delta)

delta

object

A chat completion delta generated by streamed model responses.

Hide properties

[](#chat/streaming-choices-delta-content)

content

string or null

The contents of the chunk message.

[](#chat/streaming-choices-delta-function_call)

function_call

Deprecated

object

Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model.

Hide properties

[](#chat/streaming-choices-delta-function_call-arguments)

arguments

string

The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.

[](#chat/streaming-choices-delta-function_call-name)

name

string

The name of the function to call.

[](#chat/streaming-choices-delta-tool_calls)

tool_calls

array

Hide properties

[](#chat/streaming-choices-delta-tool_calls-index)

index

integer

[](#chat/streaming-choices-delta-tool_calls-id)

id

string

The ID of the tool call.

[](#chat/streaming-choices-delta-tool_calls-type)

type

string

The type of the tool. Currently, only `function` is supported.

[](#chat/streaming-choices-delta-tool_calls-function)

function

object

Hide properties

[](#chat/streaming-choices-delta-tool_calls-function-name)

name

string

The name of the function to call.

[](#chat/streaming-choices-delta-tool_calls-function-arguments)

arguments

string

The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.

[](#chat/streaming-choices-delta-role)

role

string

The role of the author of this message.

[](#chat/streaming-choices-logprobs)

logprobs

object or null

Log probability information for the choice.

Hide properties

[](#chat/streaming-choices-logprobs-content)

content

array or null

A list of message content tokens with log probability information.

Hide properties

[](#chat/streaming-choices-logprobs-content-token)

token

string

The token.

[](#chat/streaming-choices-logprobs-content-logprob)

logprob

number

The log probability of this token.

[](#chat/streaming-choices-logprobs-content-bytes)

bytes

array or null

A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.

[](#chat/streaming-choices-logprobs-content-top_logprobs)

top_logprobs

array

List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.

Hide properties

[](#chat/streaming-choices-logprobs-content-top_logprobs-token)

token

string

The token.

[](#chat/streaming-choices-logprobs-content-top_logprobs-logprob)

logprob

number

The log probability of this token.

[](#chat/streaming-choices-logprobs-content-top_logprobs-bytes)

bytes

array or null

A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.

[](#chat/streaming-choices-finish_reason)

finish_reason

string or null

The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.

[](#chat/streaming-choices-index)

index

integer

The index of the choice in the list of choices.

[](#chat/streaming-created)

created

integer

The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.

[](#chat/streaming-model)

model

string

The model to generate the completion.

[](#chat/streaming-system_fingerprint)

system_fingerprint

string

This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#chat/streaming-object)

object

string

The object type, which is always `chat.completion.chunk`.

The chat completion chunk object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

    ....

    {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}

[

## Embeddings

](/docs/api-reference/embeddings)

Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.

Related guide: [Embeddings](/docs/guides/embeddings)

[

## Create embeddings

](/docs/api-reference/embeddings/create)

post <https://api.openai.com/v1/embeddings>

Creates an embedding vector representing the input text.

### Request body

[](#embeddings-create-input)

input

string or array

Required

Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

Hide possible types

string

string

The string that will be turned into an embedding.

array

array

The array of strings that will be turned into an embedding.

array

array

The array of integers that will be turned into an embedding.

array

array

The array of arrays containing integers that will be turned into an embedding.

[](#embeddings-create-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.

[](#embeddings-create-encoding_format)

encoding_format

string

Optional

Defaults to float

The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/).

[](#embeddings-create-dimensions)

dimensions

integer

Optional

The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.

[](#embeddings-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

### Returns

A list of [embedding](/docs/api-reference/embeddings/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    client.embeddings.create(
      model="text-embedding-ada-002",
      input="The food was delicious and the waiter...",
      encoding_format="float"
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "object": "list",
      "data": [
        {
          "object": "embedding",
          "embedding": [
            0.0023064255,
            -0.009327292,
            .... (1536 floats total for ada-002)
            -0.0028842222,
          ],
          "index": 0
        }
      ],
      "model": "text-embedding-ada-002",
      "usage": {
        "prompt_tokens": 8,
        "total_tokens": 8
      }
    }

[

## The embedding object

](/docs/api-reference/embeddings/object)

Represents an embedding vector returned by embedding endpoint.

[](#embeddings/object-index)

index

integer

The index of the embedding in the list of embeddings.

[](#embeddings/object-embedding)

embedding

array

The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

[](#embeddings/object-object)

object

string

The object type, which is always "embedding".

The embedding object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    {
      "object": "embedding",
      "embedding": [
        0.0023064255,
        -0.009327292,
        .... (1536 floats total for ada-002)
        -0.0028842222,
      ],
      "index": 0
    }

[

## Fine-tuning

](/docs/api-reference/fine-tuning)

Manage fine-tuning jobs to tailor a model to your specific training data.

Related guide: [Fine-tune models](/docs/guides/fine-tuning)

[

## Create fine-tuning job

](/docs/api-reference/fine-tuning/create)

post <https://api.openai.com/v1/fine\_tuning/jobs>

Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Request body

[](#fine-tuning-create-model)

model

string

Required

The name of the model to fine-tune. You can select one of the [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).

[](#fine-tuning-create-training_file)

training_file

string

Required

The ID of an uploaded file that contains training data.

See [upload file](/docs/api-reference/files/upload) for how to upload a file.

Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

[](#fine-tuning-create-hyperparameters)

hyperparameters

object

Optional

The hyperparameters used for the fine-tuning job.

Hide properties

[](#fine-tuning-create-hyperparameters-batch_size)

batch_size

string or integer

Optional

Defaults to auto

Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.

[](#fine-tuning-create-hyperparameters-learning_rate_multiplier)

learning_rate_multiplier

string or number

Optional

Defaults to auto

Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.

[](#fine-tuning-create-hyperparameters-n_epochs)

n_epochs

string or integer

Optional

Defaults to auto

The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.

[](#fine-tuning-create-suffix)

suffix

string or null

Optional

Defaults to null

A string of up to 18 characters that will be added to your fine-tuned model name.

For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.

[](#fine-tuning-create-validation_file)

validation_file

string or null

Optional

The ID of an uploaded file that contains validation data.

If you provide this file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in the fine-tuning results file. The same data should not be present in both train and validation files.

Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

### Returns

A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.

Default‍ Epochs‍ Validation file‍

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    from openai import OpenAI
    client = OpenAI()

    client.fine_tuning.jobs.create(
      training_file="file-abc123",
      model="gpt-3.5-turbo"
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-3.5-turbo-0125",
      "created_at": 1614807352,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "status": "queued",
      "validation_file": null,
      "training_file": "file-abc123",
    }

[

## List fine-tuning jobs

](/docs/api-reference/fine-tuning/list)

get <https://api.openai.com/v1/fine\_tuning/jobs>

List your organization's fine-tuning jobs

### Query parameters

[](#fine-tuning-list-after)

after

string

Optional

Identifier for the last job from the previous pagination request.

[](#fine-tuning-list-limit)

limit

integer

Optional

Defaults to 20

Number of fine-tuning jobs to retrieve.

### Returns

A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.fine_tuning.jobs.list()

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    {
      "object": "list",
      "data": [
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",
          "created_at": 1689813489,
          "level": "warn",
          "message": "Fine tuning process stopping due to job cancellation",
          "data": null,
          "type": "message"
        },
        { ... },
        { ... }
      ], "has_more": true
    }

[

## List fine-tuning events

](/docs/api-reference/fine-tuning/list-events)

get <https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/events>

Get status updates for a fine-tuning job.

### Path parameters

[](#fine-tuning-list-events-fine_tuning_job_id)

fine_tuning_job_id

string

Required

The ID of the fine-tuning job to get events for.

### Query parameters

[](#fine-tuning-list-events-after)

after

string

Optional

Identifier for the last event from the previous pagination request.

[](#fine-tuning-list-events-limit)

limit

integer

Optional

Defaults to 20

Number of events to retrieve.

### Returns

A list of fine-tuning event objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    from openai import OpenAI
    client = OpenAI()

    client.fine_tuning.jobs.list_events(
      fine_tuning_job_id="ftjob-abc123",
      limit=2
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    {
      "object": "list",
      "data": [
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
          "created_at": 1692407401,
          "level": "info",
          "message": "Fine tuning job successfully completed",
          "data": null,
          "type": "message"
        },
        {
          "object": "fine_tuning.job.event",
          "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
          "created_at": 1692407400,
          "level": "info",
          "message": "New fine-tuned model created: ft:gpt-3.5-turbo:openai::7p4lURel",
          "data": null,
          "type": "message"
        }
      ],
      "has_more": true
    }

[

## Retrieve fine-tuning job

](/docs/api-reference/fine-tuning/retrieve)

get <https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}>

Get info about a fine-tuning job.

[Learn more about fine-tuning](/docs/guides/fine-tuning)

### Path parameters

[](#fine-tuning-retrieve-fine_tuning_job_id)

fine_tuning_job_id

string

Required

The ID of the fine-tuning job.

### Returns

The [fine-tuning](/docs/api-reference/fine-tuning/object) object with the given ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.fine_tuning.jobs.retrieve("ftjob-abc123")

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "davinci-002",
      "created_at": 1692661014,
      "finished_at": 1692661190,
      "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
      "organization_id": "org-123",
      "result_files": [
          "file-abc123"
      ],
      "status": "succeeded",
      "validation_file": null,
      "training_file": "file-abc123",
      "hyperparameters": {
          "n_epochs": 4,
      },
      "trained_tokens": 5768
    }

[

## Cancel fine-tuning

](/docs/api-reference/fine-tuning/cancel)

post <https://api.openai.com/v1/fine\_tuning/jobs/{fine\_tuning\_job\_id}/cancel>

Immediately cancel a fine-tune job.

### Path parameters

[](#fine-tuning-cancel-fine_tuning_job_id)

fine_tuning_job_id

string

Required

The ID of the fine-tuning job to cancel.

### Returns

The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.fine_tuning.jobs.cancel("ftjob-abc123")

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "gpt-3.5-turbo-0125",
      "created_at": 1689376978,
      "fine_tuned_model": null,
      "organization_id": "org-123",
      "result_files": [],
      "hyperparameters": {
        "n_epochs":  "auto"
      },
      "status": "cancelled",
      "validation_file": "file-abc123",
      "training_file": "file-abc123"
    }

[

## The fine-tuning job object

](/docs/api-reference/fine-tuning/object)

The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.

[](#fine-tuning/object-id)

id

string

The object identifier, which can be referenced in the API endpoints.

[](#fine-tuning/object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the fine-tuning job was created.

[](#fine-tuning/object-error)

error

object or null

For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.

Hide properties

[](#fine-tuning/object-error-code)

code

string

A machine-readable error code.

[](#fine-tuning/object-error-message)

message

string

A human-readable error message.

[](#fine-tuning/object-error-param)

param

string or null

The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.

[](#fine-tuning/object-fine_tuned_model)

fine_tuned_model

string or null

The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-finished_at)

finished_at

integer or null

The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-hyperparameters)

hyperparameters

object

The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

Hide properties

[](#fine-tuning/object-hyperparameters-n_epochs)

n_epochs

string or integer

The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset. "auto" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs.

[](#fine-tuning/object-model)

model

string

The base model that is being fine-tuned.

[](#fine-tuning/object-object)

object

string

The object type, which is always "fine_tuning.job".

[](#fine-tuning/object-organization_id)

organization_id

string

The organization that owns the fine-tuning job.

[](#fine-tuning/object-result_files)

result_files

array

The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).

[](#fine-tuning/object-status)

status

string

The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.

[](#fine-tuning/object-trained_tokens)

trained_tokens

integer or null

The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.

[](#fine-tuning/object-training_file)

training_file

string

The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents).

[](#fine-tuning/object-validation_file)

validation_file

string or null

The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents).

The fine-tuning job object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    {
      "object": "fine_tuning.job",
      "id": "ftjob-abc123",
      "model": "davinci-002",
      "created_at": 1692661014,
      "finished_at": 1692661190,
      "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
      "organization_id": "org-123",
      "result_files": [
          "file-abc123"
      ],
      "status": "succeeded",
      "validation_file": null,
      "training_file": "file-abc123",
      "hyperparameters": {
          "n_epochs": 4,
      },
      "trained_tokens": 5768
    }

[

## The fine-tuning job event object

](/docs/api-reference/fine-tuning/event-object)

Fine-tuning job event object

[](#fine-tuning/event-object-id)

id

string

[](#fine-tuning/event-object-created_at)

created_at

integer

[](#fine-tuning/event-object-level)

level

string

[](#fine-tuning/event-object-message)

message

string

[](#fine-tuning/event-object-object)

object

string

The fine-tuning job event object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    {
      "object": "fine_tuning.job.event",
      "id": "ftevent-abc123"
      "created_at": 1677610602,
      "level": "info",
      "message": "Created fine-tuning job"
    }

[

## Files

](/docs/api-reference/files)

Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants) and [Fine-tuning](/docs/api-reference/fine-tuning).

[

## Upload file

](/docs/api-reference/files/create)

post <https://api.openai.com/v1/files>

Upload a file that can be used across various endpoints. The size of all the files uploaded by one organization can be up to 100 GB.

The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the [Assistants Tools guide](/docs/assistants/tools) to learn more about the types of files supported. The Fine-tuning API only supports `.jsonl` files.

Please [contact us](https://help.openai.com/) if you need to increase these storage limits.

### Request body

[](#files-create-file)

file

file

Required

The File object (not file name) to be uploaded.

[](#files-create-purpose)

purpose

string

Required

The intended purpose of the uploaded file.

Use "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning) and "assistants" for [Assistants](/docs/api-reference/assistants) and [Messages](/docs/api-reference/messages). This allows us to validate the format of the uploaded file is correct for fine-tuning.

### Returns

The uploaded [File](/docs/api-reference/files/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    from openai import OpenAI
    client = OpenAI()

    client.files.create(
      file=open("mydata.jsonl", "rb"),
      purpose="fine-tune"
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "mydata.jsonl",
      "purpose": "fine-tune",
    }

[

## List files

](/docs/api-reference/files/list)

get <https://api.openai.com/v1/files>

Returns a list of files that belong to the user's organization.

### Query parameters

[](#files-list-purpose)

purpose

string

Optional

Only return files with the given purpose.

### Returns

A list of [File](/docs/api-reference/files/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.files.list()

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    {
      "data": [
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 175,
          "created_at": 1613677385,
          "filename": "salesOverview.pdf",
          "purpose": "assistants",
        },
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 140,
          "created_at": 1613779121,
          "filename": "puppy.jsonl",
          "purpose": "fine-tune",
        }
      ],
      "object": "list"
    }

[

## Retrieve file

](/docs/api-reference/files/retrieve)

get <https://api.openai.com/v1/files/{file\_id}>

Returns information about a specific file.

### Path parameters

[](#files-retrieve-file_id)

file_id

string

Required

The ID of the file to use for this request.

### Returns

The [File](/docs/api-reference/files/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.files.retrieve("file-abc123")

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "mydata.jsonl",
      "purpose": "fine-tune",
    }

[

## Delete file

](/docs/api-reference/files/delete)

delete <https://api.openai.com/v1/files/{file\_id}>

Delete a file.

### Path parameters

[](#files-delete-file_id)

file_id

string

Required

The ID of the file to use for this request.

### Returns

Deletion status.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.files.delete("file-abc123")

Response

Copy‍

    1
    2
    3
    4
    5
    {
      "id": "file-abc123",
      "object": "file",
      "deleted": true
    }

[

## Retrieve file content

](/docs/api-reference/files/retrieve-contents)

get <https://api.openai.com/v1/files/{file\_id}/content>

Returns the contents of the specified file.

### Path parameters

[](#files-retrieve-contents-file_id)

file_id

string

Required

The ID of the file to use for this request.

### Returns

The file content.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    content = client.files.retrieve_content("file-abc123")

[

## The file object

](/docs/api-reference/files/object)

The `File` object represents a document that has been uploaded to OpenAI.

[](#files/object-id)

id

string

The file identifier, which can be referenced in the API endpoints.

[](#files/object-bytes)

bytes

integer

The size of the file, in bytes.

[](#files/object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the file was created.

[](#files/object-filename)

filename

string

The name of the file.

[](#files/object-object)

object

string

The object type, which is always `file`.

[](#files/object-purpose)

purpose

string

The intended purpose of the file. Supported values are `fine-tune`, `fine-tune-results`, `assistants`, and `assistants_output`.

[](#files/object-status)

status

Deprecated

string

Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.

[](#files/object-status_details)

status_details

Deprecated

string

Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.

The file object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    {
      "id": "file-abc123",
      "object": "file",
      "bytes": 120000,
      "created_at": 1677610602,
      "filename": "salesOverview.pdf",
      "purpose": "assistants",
    }

[

## Images

](/docs/api-reference/images)

Given a prompt and/or an input image, the model will generate a new image.

Related guide: [Image generation](/docs/guides/images)

[

## Create image

](/docs/api-reference/images/create)

post <https://api.openai.com/v1/images/generations>

Creates an image given a prompt.

### Request body

[](#images-create-prompt)

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.

[](#images-create-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation.

[](#images-create-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

[](#images-create-quality)

quality

string

Optional

Defaults to standard

The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`.

[](#images-create-response_format)

response_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

[](#images-create-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models.

[](#images-create-style)

style

string or null

Optional

Defaults to vivid

The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`.

[](#images-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    from openai import OpenAI
    client = OpenAI()

    client.images.generate(
      model="dall-e-3",
      prompt="A cute baby sea otter",
      n=1,
      size="1024x1024"
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    {
      "created": 1589478378,
      "data": [
        {
          "url": "https://..."
        },
        {
          "url": "https://..."
        }
      ]
    }

[

## Create image edit

](/docs/api-reference/images/createEdit)

post <https://api.openai.com/v1/images/edits>

Creates an edited or extended image given an original image and a prompt.

### Request body

[](#images-createedit-image)

image

file

Required

The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask.

[](#images-createedit-prompt)

prompt

string

Required

A text description of the desired image(s). The maximum length is 1000 characters.

[](#images-createedit-mask)

mask

file

Optional

An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.

[](#images-createedit-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

[](#images-createedit-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10.

[](#images-createedit-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

[](#images-createedit-response_format)

response_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

[](#images-createedit-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    from openai import OpenAI
    client = OpenAI()

    client.images.edit(
      image=open("otter.png", "rb"),
      mask=open("mask.png", "rb"),
      prompt="A cute baby sea otter wearing a beret",
      n=2,
      size="1024x1024"
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    {
      "created": 1589478378,
      "data": [
        {
          "url": "https://..."
        },
        {
          "url": "https://..."
        }
      ]
    }

[

## Create image variation

](/docs/api-reference/images/createVariation)

post <https://api.openai.com/v1/images/variations>

Creates a variation of a given image.

### Request body

[](#images-createvariation-image)

image

file

Required

The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.

[](#images-createvariation-model)

model

string

Optional

Defaults to dall-e-2

The model to use for image generation. Only `dall-e-2` is supported at this time.

[](#images-createvariation-n)

n

integer or null

Optional

Defaults to 1

The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.

[](#images-createvariation-response_format)

response_format

string or null

Optional

Defaults to url

The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.

[](#images-createvariation-size)

size

string or null

Optional

Defaults to 1024x1024

The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.

[](#images-createvariation-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

### Returns

Returns a list of [image](/docs/api-reference/images/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    response = client.images.create_variation(
      image=open("image_edit_original.png", "rb"),
      n=2,
      size="1024x1024"
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    {
      "created": 1589478378,
      "data": [
        {
          "url": "https://..."
        },
        {
          "url": "https://..."
        }
      ]
    }

[

## The image object

](/docs/api-reference/images/object)

Represents the url or the content of an image generated by the OpenAI API.

[](#images/object-b64_json)

b64_json

string

The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.

[](#images/object-url)

url

string

The URL of the generated image, if `response_format` is `url` (default).

[](#images/object-revised_prompt)

revised_prompt

string

The prompt that was used to generate the image, if there was any revision to the prompt.

The image object

Copy‍

    1
    2
    3
    4
    {
      "url": "...",
      "revised_prompt": "..."
    }

[

## Models

](/docs/api-reference/models)

List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.

[

## List models

](/docs/api-reference/models/list)

get <https://api.openai.com/v1/models>

Lists the currently available models, and provides basic information about each one such as the owner and availability.

### Returns

A list of [model](/docs/api-reference/models/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.models.list()

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    {
      "object": "list",
      "data": [
        {
          "id": "model-id-0",
          "object": "model",
          "created": 1686935002,
          "owned_by": "organization-owner"
        },
        {
          "id": "model-id-1",
          "object": "model",
          "created": 1686935002,
          "owned_by": "organization-owner",
        },
        {
          "id": "model-id-2",
          "object": "model",
          "created": 1686935002,
          "owned_by": "openai"
        },
      ],
      "object": "list"
    }

[

## Retrieve model

](/docs/api-reference/models/retrieve)

get <https://api.openai.com/v1/models/{model}>

Retrieves a model instance, providing basic information about the model such as the owner and permissioning.

### Path parameters

[](#models-retrieve-model)

model

string

Required

The ID of the model to use for this request

### Returns

The [model](/docs/api-reference/models/object) object matching the specified ID.

Example request

gpt-3.5-turbo-instruct

gpt-3.5-turbo-instruct-0914 babbage-002 gpt-3.5-turbo-instruct davinci-002

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.models.retrieve("gpt-3.5-turbo-instruct")

Response

gpt-3.5-turbo-instruct

gpt-3.5-turbo-instruct-0914 babbage-002 gpt-3.5-turbo-instruct davinci-002

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "gpt-3.5-turbo-instruct",
      "object": "model",
      "created": 1686935002,
      "owned_by": "openai"
    }

[

## Delete a fine-tuned model

](/docs/api-reference/models/delete)

delete <https://api.openai.com/v1/models/{model}>

Delete a fine-tuned model. You must have the Owner role in your organization to delete a model.

### Path parameters

[](#models-delete-model)

model

string

Required

The model to delete

### Returns

Deletion status.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    from openai import OpenAI
    client = OpenAI()

    client.models.delete("ft:gpt-3.5-turbo:acemeco:suffix:abc123")

Response

Copy‍

    1
    2
    3
    4
    5
    {
      "id": "ft:gpt-3.5-turbo:acemeco:suffix:abc123",
      "object": "model",
      "deleted": true
    }

[

## The model object

](/docs/api-reference/models/object)

Describes an OpenAI model offering that can be used with the API.

[](#models/object-id)

id

string

The model identifier, which can be referenced in the API endpoints.

[](#models/object-created)

created

integer

The Unix timestamp (in seconds) when the model was created.

[](#models/object-object)

object

string

The object type, which is always "model".

[](#models/object-owned_by)

owned_by

string

The organization that owns the model.

The model object

gpt-4-vision-preview dall-e-3 gpt-4-turbo-preview gpt-3.5-turbo-0613 dall-e-2 gpt-3.5-turbo-instruct-0914 tts-1-hd-1106 tts-1-hd babbage-002 gpt-3.5-turbo-instruct gpt-3.5-turbo-0125 gpt-3.5-turbo davinci-002 gpt-3.5-turbo-0301 tts-1 tts-1-1106 gpt-3.5-turbo-1106 gpt-3.5-turbo-16k gpt-4 gpt-4-0613 gpt-3.5-turbo-16k-0613 gpt-4-1106-preview gpt-4-0125-preview

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "davinci",
      "object": "model",
      "created": 1686935002,
      "owned_by": "openai"
    }

[

## Moderations

](/docs/api-reference/moderations)

Given some input text, outputs if the model classifies it as potentially harmful across several categories.

Related guide: [Moderations](/docs/guides/moderation)

[

## Create moderation

](/docs/api-reference/moderations/create)

post <https://api.openai.com/v1/moderations>

Classifies if text is potentially harmful.

### Request body

[](#moderations-create-input)

input

string or array

Required

The input text to classify

[](#moderations-create-model)

model

string

Optional

Defaults to text-moderation-latest

Two content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.

The default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.

### Returns

A [moderation](/docs/api-reference/moderations/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    moderation = client.moderations.create(input="I want to kill them.")
    print(moderation)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    {
      "id": "modr-XXXXX",
      "model": "text-moderation-005",
      "results": [
        {
          "flagged": true,
          "categories": {
            "sexual": false,
            "hate": false,
            "harassment": false,
            "self-harm": false,
            "sexual/minors": false,
            "hate/threatening": false,
            "violence/graphic": false,
            "self-harm/intent": false,
            "self-harm/instructions": false,
            "harassment/threatening": true,
            "violence": true,
          },
          "category_scores": {
            "sexual": 1.2282071e-06,
            "hate": 0.010696256,
            "harassment": 0.29842457,
            "self-harm": 1.5236925e-08,
            "sexual/minors": 5.7246268e-08,
            "hate/threatening": 0.0060676364,
            "violence/graphic": 4.435014e-06,
            "self-harm/intent": 8.098441e-10,
            "self-harm/instructions": 2.8498655e-11,
            "harassment/threatening": 0.63055265,
            "violence": 0.99011886,
          }
        }
      ]
    }

[

## The moderation object

](/docs/api-reference/moderations/object)

Represents if a given text input is potentially harmful.

[](#moderations/object-id)

id

string

The unique identifier for the moderation request.

[](#moderations/object-model)

model

string

The model used to generate the moderation results.

[](#moderations/object-results)

results

array

A list of moderation objects.

Hide properties

[](#moderations/object-results-flagged)

flagged

boolean

Whether any of the below categories are flagged.

[](#moderations/object-results-categories)

categories

object

A list of the categories, and whether they are flagged or not.

Hide properties

[](#moderations/object-results-categories-hate)

hate

boolean

Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment.

[](#moderations/object-results-categories-hate-threatening)

hate/threatening

boolean

Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.

[](#moderations/object-results-categories-harassment)

harassment

boolean

Content that expresses, incites, or promotes harassing language towards any target.

[](#moderations/object-results-categories-harassment-threatening)

harassment/threatening

boolean

Harassment content that also includes violence or serious harm towards any target.

[](#moderations/object-results-categories-self-harm)

self-harm

boolean

Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.

[](#moderations/object-results-categories-self-harm-intent)

self-harm/intent

boolean

Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.

[](#moderations/object-results-categories-self-harm-instructions)

self-harm/instructions

boolean

Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.

[](#moderations/object-results-categories-sexual)

sexual

boolean

Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).

[](#moderations/object-results-categories-sexual-minors)

sexual/minors

boolean

Sexual content that includes an individual who is under 18 years old.

[](#moderations/object-results-categories-violence)

violence

boolean

Content that depicts death, violence, or physical injury.

[](#moderations/object-results-categories-violence-graphic)

violence/graphic

boolean

Content that depicts death, violence, or physical injury in graphic detail.

[](#moderations/object-results-category_scores)

category_scores

object

A list of the categories along with their scores as predicted by model.

Hide properties

[](#moderations/object-results-category_scores-hate)

hate

number

The score for the category 'hate'.

[](#moderations/object-results-category_scores-hate-threatening)

hate/threatening

number

The score for the category 'hate/threatening'.

[](#moderations/object-results-category_scores-harassment)

harassment

number

The score for the category 'harassment'.

[](#moderations/object-results-category_scores-harassment-threatening)

harassment/threatening

number

The score for the category 'harassment/threatening'.

[](#moderations/object-results-category_scores-self-harm)

self-harm

number

The score for the category 'self-harm'.

[](#moderations/object-results-category_scores-self-harm-intent)

self-harm/intent

number

The score for the category 'self-harm/intent'.

[](#moderations/object-results-category_scores-self-harm-instructions)

self-harm/instructions

number

The score for the category 'self-harm/instructions'.

[](#moderations/object-results-category_scores-sexual)

sexual

number

The score for the category 'sexual'.

[](#moderations/object-results-category_scores-sexual-minors)

sexual/minors

number

The score for the category 'sexual/minors'.

[](#moderations/object-results-category_scores-violence)

violence

number

The score for the category 'violence'.

[](#moderations/object-results-category_scores-violence-graphic)

violence/graphic

number

The score for the category 'violence/graphic'.

The moderation object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    {
      "id": "modr-XXXXX",
      "model": "text-moderation-005",
      "results": [
        {
          "flagged": true,
          "categories": {
            "sexual": false,
            "hate": false,
            "harassment": false,
            "self-harm": false,
            "sexual/minors": false,
            "hate/threatening": false,
            "violence/graphic": false,
            "self-harm/intent": false,
            "self-harm/instructions": false,
            "harassment/threatening": true,
            "violence": true,
          },
          "category_scores": {
            "sexual": 1.2282071e-06,
            "hate": 0.010696256,
            "harassment": 0.29842457,
            "self-harm": 1.5236925e-08,
            "sexual/minors": 5.7246268e-08,
            "hate/threatening": 0.0060676364,
            "violence/graphic": 4.435014e-06,
            "self-harm/intent": 8.098441e-10,
            "self-harm/instructions": 2.8498655e-11,
            "harassment/threatening": 0.63055265,
            "violence": 0.99011886,
          }
        }
      ]
    }

[

Assistants

Beta

---

](/docs/api-reference/assistants)

Build assistants that can call models and use tools to perform tasks.

[Get started with the Assistants API](/docs/assistants)

[

Create assistant

Beta

---

](/docs/api-reference/assistants/createAssistant)

post <https://api.openai.com/v1/assistants>

Create an assistant with a model and instructions.

### Request body

[](#assistants-createassistant-model)

model

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.

[](#assistants-createassistant-name)

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

[](#assistants-createassistant-description)

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

[](#assistants-createassistant-instructions)

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 32768 characters.

[](#assistants-createassistant-tools)

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Hide possible types

Code interpreter tool

object

Hide properties

[](#assistants-createassistant-tools-code-interpreter-tool-type)

type

string

Required

The type of tool being defined: `code_interpreter`

Retrieval tool

object

Hide properties

[](#assistants-createassistant-tools-retrieval-tool-type)

type

string

Required

The type of tool being defined: `retrieval`

Function tool

object

Hide properties

[](#assistants-createassistant-tools-function-tool-type)

type

string

Required

The type of tool being defined: `function`

[](#assistants-createassistant-tools-function-tool-function)

function

object

Required

Hide properties

[](#assistants-createassistant-tools-function-tool-function-description)

description

string

Optional

A description of what the function does, used by the model to choose when and how to call the function.

[](#assistants-createassistant-tools-function-tool-function-name)

name

string

Required

The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

[](#assistants-createassistant-tools-function-tool-function-parameters)

parameters

object

Optional

The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.

Omitting `parameters` defines a function with an empty parameter list.

[](#assistants-createassistant-file_ids)

file_ids

array

Optional

Defaults to \[\]

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

[](#assistants-createassistant-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

An [assistant](/docs/api-reference/assistants/object) object.

Code Interpreter‍ Files‍

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    from openai import OpenAI
    client = OpenAI()

    my_assistant = client.beta.assistants.create(
        instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
        name="Math Tutor",
        tools=[{"type": "code_interpreter"}],
        model="gpt-4",
    )
    print(my_assistant)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698984975,
      "name": "Math Tutor",
      "description": null,
      "model": "gpt-4",
      "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [],
      "metadata": {}
    }

[

Create assistant file

Beta

---

](/docs/api-reference/assistants/createAssistantFile)

post <https://api.openai.com/v1/assistants/{assistant\_id}/files>

Create an assistant file by attaching a [File](/docs/api-reference/files) to an [assistant](/docs/api-reference/assistants).

### Path parameters

[](#assistants-createassistantfile-assistant_id)

assistant_id

string

Required

The ID of the assistant for which to create a File.

### Request body

[](#assistants-createassistantfile-file_id)

file_id

string

Required

A [File](/docs/api-reference/files) ID (with `purpose="assistants"`) that the assistant should use. Useful for tools like `retrieval` and `code_interpreter` that can access files.

### Returns

An [assistant file](/docs/api-reference/assistants/file-object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    assistant_file = client.beta.assistants.files.create(
      assistant_id="asst_abc123",
      file_id="file-abc123"
    )
    print(assistant_file)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "file-abc123",
      "object": "assistant.file",
      "created_at": 1699055364,
      "assistant_id": "asst_abc123"
    }

[

List assistants

Beta

---

](/docs/api-reference/assistants/listAssistants)

get <https://api.openai.com/v1/assistants>

Returns a list of assistants.

### Query parameters

[](#assistants-listassistants-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#assistants-listassistants-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#assistants-listassistants-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

[](#assistants-listassistants-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant](/docs/api-reference/assistants/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    my_assistants = client.beta.assistants.list(
        order="desc",
        limit="20",
    )
    print(my_assistants.data)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    {
      "object": "list",
      "data": [
        {
          "id": "asst_abc123",
          "object": "assistant",
          "created_at": 1698982736,
          "name": "Coding Tutor",
          "description": null,
          "model": "gpt-4",
          "instructions": "You are a helpful assistant designed to make me better at coding!",
          "tools": [],
          "file_ids": [],
          "metadata": {}
        },
        {
          "id": "asst_abc456",
          "object": "assistant",
          "created_at": 1698982718,
          "name": "My Assistant",
          "description": null,
          "model": "gpt-4",
          "instructions": "You are a helpful assistant designed to make me better at coding!",
          "tools": [],
          "file_ids": [],
          "metadata": {}
        },
        {
          "id": "asst_abc789",
          "object": "assistant",
          "created_at": 1698982643,
          "name": null,
          "description": null,
          "model": "gpt-4",
          "instructions": null,
          "tools": [],
          "file_ids": [],
          "metadata": {}
        }
      ],
      "first_id": "asst_abc123",
      "last_id": "asst_abc789",
      "has_more": false
    }

[

List assistant files

Beta

---

](/docs/api-reference/assistants/listAssistantFiles)

get <https://api.openai.com/v1/assistants/{assistant\_id}/files>

Returns a list of assistant files.

### Path parameters

[](#assistants-listassistantfiles-assistant_id)

assistant_id

string

Required

The ID of the assistant the file belongs to.

### Query parameters

[](#assistants-listassistantfiles-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#assistants-listassistantfiles-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#assistants-listassistantfiles-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

[](#assistants-listassistantfiles-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

### Returns

A list of [assistant file](/docs/api-reference/assistants/file-object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    from openai import OpenAI
    client = OpenAI()

    assistant_files = client.beta.assistants.files.list(
      assistant_id="asst_abc123"
    )
    print(assistant_files)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "object": "list",
      "data": [
        {
          "id": "file-abc123",
          "object": "assistant.file",
          "created_at": 1699060412,
          "assistant_id": "asst_abc123"
        },
        {
          "id": "file-abc456",
          "object": "assistant.file",
          "created_at": 1699060412,
          "assistant_id": "asst_abc123"
        }
      ],
      "first_id": "file-abc123",
      "last_id": "file-abc456",
      "has_more": false
    }

[

Retrieve assistant

Beta

---

](/docs/api-reference/assistants/getAssistant)

get <https://api.openai.com/v1/assistants/{assistant\_id}>

Retrieves an assistant.

### Path parameters

[](#assistants-getassistant-assistant_id)

assistant_id

string

Required

The ID of the assistant to retrieve.

### Returns

The [assistant](/docs/api-reference/assistants/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    my_assistant = client.beta.assistants.retrieve("asst_abc123")
    print(my_assistant)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1699009709,
      "name": "HR Helper",
      "description": null,
      "model": "gpt-4",
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
      "tools": [
        {
          "type": "retrieval"
        }
      ],
      "file_ids": [
        "file-abc123"
      ],
      "metadata": {}
    }

[

Retrieve assistant file

Beta

---

](/docs/api-reference/assistants/getAssistantFile)

get <https://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}>

Retrieves an AssistantFile.

### Path parameters

[](#assistants-getassistantfile-assistant_id)

assistant_id

string

Required

The ID of the assistant who the file belongs to.

[](#assistants-getassistantfile-file_id)

file_id

string

Required

The ID of the file we're getting.

### Returns

The [assistant file](/docs/api-reference/assistants/file-object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    assistant_file = client.beta.assistants.files.retrieve(
      assistant_id="asst_abc123",
      file_id="file-abc123"
    )
    print(assistant_file)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "file-abc123",
      "object": "assistant.file",
      "created_at": 1699055364,
      "assistant_id": "asst_abc123"
    }

[

Modify assistant

Beta

---

](/docs/api-reference/assistants/modifyAssistant)

post <https://api.openai.com/v1/assistants/{assistant\_id}>

Modifies an assistant.

### Path parameters

[](#assistants-modifyassistant-assistant_id)

assistant_id

string

Required

The ID of the assistant to modify.

### Request body

[](#assistants-modifyassistant-model)

model

Optional

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.

[](#assistants-modifyassistant-name)

name

string or null

Optional

The name of the assistant. The maximum length is 256 characters.

[](#assistants-modifyassistant-description)

description

string or null

Optional

The description of the assistant. The maximum length is 512 characters.

[](#assistants-modifyassistant-instructions)

instructions

string or null

Optional

The system instructions that the assistant uses. The maximum length is 32768 characters.

[](#assistants-modifyassistant-tools)

tools

array

Optional

Defaults to \[\]

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Hide possible types

Code interpreter tool

object

Hide properties

[](#assistants-modifyassistant-tools-code-interpreter-tool-type)

type

string

Required

The type of tool being defined: `code_interpreter`

Retrieval tool

object

Hide properties

[](#assistants-modifyassistant-tools-retrieval-tool-type)

type

string

Required

The type of tool being defined: `retrieval`

Function tool

object

Hide properties

[](#assistants-modifyassistant-tools-function-tool-type)

type

string

Required

The type of tool being defined: `function`

[](#assistants-modifyassistant-tools-function-tool-function)

function

object

Required

Hide properties

[](#assistants-modifyassistant-tools-function-tool-function-description)

description

string

Optional

A description of what the function does, used by the model to choose when and how to call the function.

[](#assistants-modifyassistant-tools-function-tool-function-name)

name

string

Required

The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

[](#assistants-modifyassistant-tools-function-tool-function-parameters)

parameters

object

Optional

The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.

Omitting `parameters` defines a function with an empty parameter list.

[](#assistants-modifyassistant-file_ids)

file_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order. If a file was previously attached to the list but does not show up in the list, it will be deleted from the assistant.

[](#assistants-modifyassistant-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [assistant](/docs/api-reference/assistants/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    from openai import OpenAI
    client = OpenAI()

    my_updated_assistant = client.beta.assistants.update(
      "asst_abc123",
      instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      name="HR Helper",
      tools=[{"type": "retrieval"}],
      model="gpt-4",
      file_ids=["file-abc123", "file-abc456"],
    )

    print(my_updated_assistant)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1699009709,
      "name": "HR Helper",
      "description": null,
      "model": "gpt-4",
      "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
      "tools": [
        {
          "type": "retrieval"
        }
      ],
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ],
      "metadata": {}
    }

[

Delete assistant

Beta

---

](/docs/api-reference/assistants/deleteAssistant)

delete <https://api.openai.com/v1/assistants/{assistant\_id}>

Delete an assistant.

### Path parameters

[](#assistants-deleteassistant-assistant_id)

assistant_id

string

Required

The ID of the assistant to delete.

### Returns

Deletion status

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    response = client.beta.assistants.delete("asst_abc123")
    print(response)

Response

Copy‍

    1
    2
    3
    4
    5
    {
      "id": "asst_abc123",
      "object": "assistant.deleted",
      "deleted": true
    }

[

Delete assistant file

Beta

---

](/docs/api-reference/assistants/deleteAssistantFile)

delete <https://api.openai.com/v1/assistants/{assistant\_id}/files/{file\_id}>

Delete an assistant file.

### Path parameters

[](#assistants-deleteassistantfile-assistant_id)

assistant_id

string

Required

The ID of the assistant that the file belongs to.

[](#assistants-deleteassistantfile-file_id)

file_id

string

Required

The ID of the file to delete.

### Returns

Deletion status

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    deleted_assistant_file = client.beta.assistants.files.delete(
        assistant_id="asst_abc123",
        file_id="file-abc123"
    )
    print(deleted_assistant_file)

Response

Copy‍

    1
    2
    3
    4
    5
    {
      id: "file-abc123",
      object: "assistant.file.deleted",
      deleted: true
    }

[

The assistant object

Beta

---

](/docs/api-reference/assistants/object)

Represents an `assistant` that can call the model and use tools.

[](#assistants/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#assistants/object-object)

object

string

The object type, which is always `assistant`.

[](#assistants/object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the assistant was created.

[](#assistants/object-name)

name

string or null

The name of the assistant. The maximum length is 256 characters.

[](#assistants/object-description)

description

string or null

The description of the assistant. The maximum length is 512 characters.

[](#assistants/object-model)

model

string

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.

[](#assistants/object-instructions)

instructions

string or null

The system instructions that the assistant uses. The maximum length is 32768 characters.

[](#assistants/object-tools)

tools

array

A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `retrieval`, or `function`.

Hide possible types

Code interpreter tool

object

Hide properties

[](#assistants/object-tools-code-interpreter-tool-type)

type

string

The type of tool being defined: `code_interpreter`

Retrieval tool

object

Hide properties

[](#assistants/object-tools-retrieval-tool-type)

type

string

The type of tool being defined: `retrieval`

Function tool

object

Hide properties

[](#assistants/object-tools-function-tool-type)

type

string

The type of tool being defined: `function`

[](#assistants/object-tools-function-tool-function)

function

object

Hide properties

[](#assistants/object-tools-function-tool-function-description)

description

string

A description of what the function does, used by the model to choose when and how to call the function.

[](#assistants/object-tools-function-tool-function-name)

name

string

The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

[](#assistants/object-tools-function-tool-function-parameters)

parameters

object

The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.

Omitting `parameters` defines a function with an empty parameter list.

[](#assistants/object-file_ids)

file_ids

array

A list of [file](/docs/api-reference/files) IDs attached to this assistant. There can be a maximum of 20 files attached to the assistant. Files are ordered by their creation date in ascending order.

[](#assistants/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

The assistant object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    {
      "id": "asst_abc123",
      "object": "assistant",
      "created_at": 1698984975,
      "name": "Math Tutor",
      "description": null,
      "model": "gpt-4",
      "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [],
      "metadata": {}
    }

[

The assistant file object

Beta

---

](/docs/api-reference/assistants/file-object)

A list of [Files](/docs/api-reference/files) attached to an `assistant`.

[](#assistants/file-object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#assistants/file-object-object)

object

string

The object type, which is always `assistant.file`.

[](#assistants/file-object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the assistant file was created.

[](#assistants/file-object-assistant_id)

assistant_id

string

The assistant ID that the file is attached to.

The assistant file object

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "file-abc123",
      "object": "assistant.file",
      "created_at": 1699055364,
      "assistant_id": "asst_abc123"
    }

[

Threads

Beta

---

](/docs/api-reference/threads)

Create threads that assistants can interact with.

Related guide: [Assistants](/docs/assistants/overview)

[

Create thread

Beta

---

](/docs/api-reference/threads/createThread)

post <https://api.openai.com/v1/threads>

Create a thread.

### Request body

[](#threads-createthread-messages)

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Hide properties

[](#threads-createthread-messages-role)

role

string

Required

The role of the entity that is creating the message. Currently only `user` is supported.

[](#threads-createthread-messages-content)

content

string

Required

The content of the message.

[](#threads-createthread-messages-file_ids)

file_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

[](#threads-createthread-messages-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

[](#threads-createthread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [thread](/docs/api-reference/threads) object.

Empty‍ Messages‍

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    empty_thread = client.beta.threads.create()
    print(empty_thread)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699012949,
      "metadata": {}
    }

[

Retrieve thread

Beta

---

](/docs/api-reference/threads/getThread)

get <https://api.openai.com/v1/threads/{thread\_id}>

Retrieves a thread.

### Path parameters

[](#threads-getthread-thread_id)

thread_id

string

Required

The ID of the thread to retrieve.

### Returns

The [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    my_thread = client.beta.threads.retrieve("thread_abc123")
    print(my_thread)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699014083,
      "metadata": {}
    }

[

Modify thread

Beta

---

](/docs/api-reference/threads/modifyThread)

post <https://api.openai.com/v1/threads/{thread\_id}>

Modifies a thread.

### Path parameters

[](#threads-modifythread-thread_id)

thread_id

string

Required

The ID of the thread to modify. Only the `metadata` can be modified.

### Request body

[](#threads-modifythread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [thread](/docs/api-reference/threads/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    from openai import OpenAI
    client = OpenAI()

    my_updated_thread = client.beta.threads.update(
      "thread_abc123",
      metadata={
        "modified": "true",
        "user": "abc123"
      }
    )
    print(my_updated_thread)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1699014083,
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }

[

Delete thread

Beta

---

](/docs/api-reference/threads/deleteThread)

delete <https://api.openai.com/v1/threads/{thread\_id}>

Delete a thread.

### Path parameters

[](#threads-deletethread-thread_id)

thread_id

string

Required

The ID of the thread to delete.

### Returns

Deletion status

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    response = client.beta.threads.delete("thread_abc123")
    print(response)

Response

Copy‍

    1
    2
    3
    4
    5
    {
      "id": "thread_abc123",
      "object": "thread.deleted",
      "deleted": true
    }

[

The thread object

Beta

---

](/docs/api-reference/threads/object)

Represents a thread that contains [messages](/docs/api-reference/messages).

[](#threads/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#threads/object-object)

object

string

The object type, which is always `thread`.

[](#threads/object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the thread was created.

[](#threads/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

The thread object

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "thread_abc123",
      "object": "thread",
      "created_at": 1698107661,
      "metadata": {}
    }

[

Messages

Beta

---

](/docs/api-reference/messages)

Create messages within threads

Related guide: [Assistants](/docs/assistants/overview)

[

Create message

Beta

---

](/docs/api-reference/messages/createMessage)

post <https://api.openai.com/v1/threads/{thread\_id}/messages>

Create a message.

### Path parameters

[](#messages-createmessage-thread_id)

thread_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to create a message for.

### Request body

[](#messages-createmessage-role)

role

string

Required

The role of the entity that is creating the message. Currently only `user` is supported.

[](#messages-createmessage-content)

content

string

Required

The content of the message.

[](#messages-createmessage-file_ids)

file_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

[](#messages-createmessage-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [message](/docs/api-reference/messages/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    from openai import OpenAI
    client = OpenAI()

    thread_message = client.beta.threads.messages.create(
      "thread_abc123",
      role="user",
      content="How does AI work? Explain it in simple terms.",
    )
    print(thread_message)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "thread_id": "thread_abc123",
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "assistant_id": null,
      "run_id": null,
      "metadata": {}
    }

[

List messages

Beta

---

](/docs/api-reference/messages/listMessages)

get <https://api.openai.com/v1/threads/{thread\_id}/messages>

Returns a list of messages for a given thread.

### Path parameters

[](#messages-listmessages-thread_id)

thread_id

string

Required

The ID of the [thread](/docs/api-reference/threads) the messages belong to.

### Query parameters

[](#messages-listmessages-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#messages-listmessages-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#messages-listmessages-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

[](#messages-listmessages-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

### Returns

A list of [message](/docs/api-reference/messages) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    from openai import OpenAI
    client = OpenAI()

    thread_messages = client.beta.threads.messages.list("thread_abc123")
    print(thread_messages.data)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    48
    49
    50
    {
      "object": "list",
      "data": [
        {
          "id": "msg_abc123",
          "object": "thread.message",
          "created_at": 1699016383,
          "thread_id": "thread_abc123",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "How does AI work? Explain it in simple terms.",
                "annotations": []
              }
            }
          ],
          "file_ids": [],
          "assistant_id": null,
          "run_id": null,
          "metadata": {}
        },
        {
          "id": "msg_abc456",
          "object": "thread.message",
          "created_at": 1699016383,
          "thread_id": "thread_abc123",
          "role": "user",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "Hello, what is AI?",
                "annotations": []
              }
            }
          ],
          "file_ids": [
            "file-abc123"
          ],
          "assistant_id": null,
          "run_id": null,
          "metadata": {}
        }
      ],
      "first_id": "msg_abc123",
      "last_id": "msg_abc456",
      "has_more": false
    }

[

List message files

Beta

---

](/docs/api-reference/messages/listMessageFiles)

get <https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files>

Returns a list of message files.

### Path parameters

[](#messages-listmessagefiles-thread_id)

thread_id

string

Required

The ID of the thread that the message and files belong to.

[](#messages-listmessagefiles-message_id)

message_id

string

Required

The ID of the message that the files belongs to.

### Query parameters

[](#messages-listmessagefiles-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#messages-listmessagefiles-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#messages-listmessagefiles-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

[](#messages-listmessagefiles-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

### Returns

A list of [message file](/docs/api-reference/messages/file-object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    message_files = client.beta.threads.messages.files.list(
      thread_id="thread_abc123",
      message_id="msg_abc123"
    )
    print(message_files)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "object": "list",
      "data": [
        {
          "id": "file-abc123",
          "object": "thread.message.file",
          "created_at": 1699061776,
          "message_id": "msg_abc123"
        },
        {
          "id": "file-abc123",
          "object": "thread.message.file",
          "created_at": 1699061776,
          "message_id": "msg_abc123"
        }
      ],
      "first_id": "file-abc123",
      "last_id": "file-abc123",
      "has_more": false
    }

[

Retrieve message

Beta

---

](/docs/api-reference/messages/getMessage)

get <https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}>

Retrieve a message.

### Path parameters

[](#messages-getmessage-thread_id)

thread_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this message belongs.

[](#messages-getmessage-message_id)

message_id

string

Required

The ID of the message to retrieve.

### Returns

The [message](/docs/api-reference/threads/messages/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    message = client.beta.threads.messages.retrieve(
      message_id="msg_abc123",
      thread_id="thread_abc123",
    )
    print(message)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "thread_id": "thread_abc123",
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "assistant_id": null,
      "run_id": null,
      "metadata": {}
    }

[

Retrieve message file

Beta

---

](/docs/api-reference/messages/getMessageFile)

get <https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}/files/{file\_id}>

Retrieves a message file.

### Path parameters

[](#messages-getmessagefile-thread_id)

thread_id

string

Required

The ID of the thread to which the message and File belong.

[](#messages-getmessagefile-message_id)

message_id

string

Required

The ID of the message the file belongs to.

[](#messages-getmessagefile-file_id)

file_id

string

Required

The ID of the file being retrieved.

### Returns

The [message file](/docs/api-reference/messages/file-object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    from openai import OpenAI
    client = OpenAI()

    message_files = client.beta.threads.messages.files.retrieve(
        thread_id="thread_abc123",
        message_id="msg_abc123",
        file_id="file-abc123"
    )
    print(message_files)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    {
      "id": "file-abc123",
      "object": "thread.message.file",
      "created_at": 1699061776,
      "message_id": "msg_abc123"
    }

[

Modify message

Beta

---

](/docs/api-reference/messages/modifyMessage)

post <https://api.openai.com/v1/threads/{thread\_id}/messages/{message\_id}>

Modifies a message.

### Path parameters

[](#messages-modifymessage-thread_id)

thread_id

string

Required

The ID of the thread to which this message belongs.

[](#messages-modifymessage-message_id)

message_id

string

Required

The ID of the message to modify.

### Request body

[](#messages-modifymessage-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [message](/docs/api-reference/threads/messages/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    from openai import OpenAI
    client = OpenAI()

    message = client.beta.threads.messages.update(
      message_id="msg_abc12",
      thread_id="thread_abc123",
      metadata={
        "modified": "true",
        "user": "abc123",
      },
    )
    print(message)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1699017614,
      "thread_id": "thread_abc123",
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "How does AI work? Explain it in simple terms.",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "assistant_id": null,
      "run_id": null,
      "metadata": {
        "modified": "true",
        "user": "abc123"
      }
    }

[

The message object

Beta

---

](/docs/api-reference/messages/object)

Represents a message within a [thread](/docs/api-reference/threads).

[](#messages/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#messages/object-object)

object

string

The object type, which is always `thread.message`.

[](#messages/object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the message was created.

[](#messages/object-thread_id)

thread_id

string

The [thread](/docs/api-reference/threads) ID that this message belongs to.

[](#messages/object-role)

role

string

The entity that produced the message. One of `user` or `assistant`.

[](#messages/object-content)

content

array

The content of the message in array of text and/or images.

Show possible types

[](#messages/object-assistant_id)

assistant_id

string or null

If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message.

[](#messages/object-run_id)

run_id

string or null

If applicable, the ID of the [run](/docs/api-reference/runs) associated with the authoring of this message.

[](#messages/object-file_ids)

file_ids

array

A list of [file](/docs/api-reference/files) IDs that the assistant should use. Useful for tools like retrieval and code_interpreter that can access files. A maximum of 10 files can be attached to a message.

[](#messages/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

The message object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "id": "msg_abc123",
      "object": "thread.message",
      "created_at": 1698983503,
      "thread_id": "thread_abc123",
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": {
            "value": "Hi! How can I help you today?",
            "annotations": []
          }
        }
      ],
      "file_ids": [],
      "assistant_id": "asst_abc123",
      "run_id": "run_abc123",
      "metadata": {}
    }

[

The message file object

Beta

---

](/docs/api-reference/messages/file-object)

A list of files attached to a `message`.

[](#messages/file-object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#messages/file-object-object)

object

string

The object type, which is always `thread.message.file`.

[](#messages/file-object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the message file was created.

[](#messages/file-object-message_id)

message_id

string

The ID of the [message](/docs/api-reference/messages) that the [File](/docs/api-reference/files) is attached to.

The message file object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    {
      "id": "file-abc123",
      "object": "thread.message.file",
      "created_at": 1698107661,
      "message_id": "message_QLoItBbqwyAJEzlTy4y9kOMM",
      "file_id": "file-abc123"
    }

[

Runs

Beta

---

](/docs/api-reference/runs)

Represents an execution run on a thread.

Related guide: [Assistants](/docs/assistants/overview)

[

Create run

Beta

---

](/docs/api-reference/runs/createRun)

post <https://api.openai.com/v1/threads/{thread\_id}/runs>

Create a run.

### Path parameters

[](#runs-createrun-thread_id)

thread_id

string

Required

The ID of the thread to run.

### Request body

[](#runs-createrun-assistant_id)

assistant_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

[](#runs-createrun-model)

model

string or null

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

[](#runs-createrun-instructions)

instructions

string or null

Optional

Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.

[](#runs-createrun-additional_instructions)

additional_instructions

string or null

Optional

Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.

[](#runs-createrun-tools)

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

Hide possible types

Code interpreter tool

object

Hide properties

[](#runs-createrun-tools-code-interpreter-tool-type)

type

string

Required

The type of tool being defined: `code_interpreter`

Retrieval tool

object

Hide properties

[](#runs-createrun-tools-retrieval-tool-type)

type

string

Required

The type of tool being defined: `retrieval`

Function tool

object

Hide properties

[](#runs-createrun-tools-function-tool-type)

type

string

Required

The type of tool being defined: `function`

[](#runs-createrun-tools-function-tool-function)

function

object

Required

Hide properties

[](#runs-createrun-tools-function-tool-function-description)

description

string

Optional

A description of what the function does, used by the model to choose when and how to call the function.

[](#runs-createrun-tools-function-tool-function-name)

name

string

Required

The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

[](#runs-createrun-tools-function-tool-function-parameters)

parameters

object

Optional

The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.

Omitting `parameters` defines a function with an empty parameter list.

[](#runs-createrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [run](/docs/api-reference/runs/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    run = client.beta.threads.runs.create(
      thread_id="thread_abc123",
      assistant_id="asst_abc123"
    )
    print(run)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699063290,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": 1699063290,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699063291,
      "last_error": null,
      "model": "gpt-4",
      "instructions": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ],
      "metadata": {},
      "usage": null
    }

[

Create thread and run

Beta

---

](/docs/api-reference/runs/createThreadAndRun)

post <https://api.openai.com/v1/threads/runs>

Create a thread and run it in one request.

### Request body

[](#runs-createthreadandrun-assistant_id)

assistant_id

string

Required

The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run.

[](#runs-createthreadandrun-thread)

thread

object

Optional

Hide properties

[](#runs-createthreadandrun-thread-messages)

messages

array

Optional

A list of [messages](/docs/api-reference/messages) to start the thread with.

Hide properties

[](#runs-createthreadandrun-thread-messages-role)

role

string

Required

The role of the entity that is creating the message. Currently only `user` is supported.

[](#runs-createthreadandrun-thread-messages-content)

content

string

Required

The content of the message.

[](#runs-createthreadandrun-thread-messages-file_ids)

file_ids

array

Optional

Defaults to \[\]

A list of [File](/docs/api-reference/files) IDs that the message should use. There can be a maximum of 10 files attached to a message. Useful for tools like `retrieval` and `code_interpreter` that can access and use files.

[](#runs-createthreadandrun-thread-messages-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

[](#runs-createthreadandrun-thread-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

[](#runs-createthreadandrun-model)

model

string or null

Optional

The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.

[](#runs-createthreadandrun-instructions)

instructions

string or null

Optional

Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.

[](#runs-createthreadandrun-tools)

tools

array or null

Optional

Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.

[](#runs-createthreadandrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

A [run](/docs/api-reference/runs/object) object.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    from openai import OpenAI
    client = OpenAI()

    run = client.beta.threads.create_and_run(
      assistant_id="asst_abc123",
      thread={
        "messages": [
          {"role": "user", "content": "Explain deep learning to a 5 year old."}
        ]
      }
    )

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699076792,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": null,
      "expires_at": 1699077392,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4",
      "instructions": "You are a helpful assistant.",
      "tools": [],
      "file_ids": [],
      "metadata": {},
      "usage": null
    }

[

List runs

Beta

---

](/docs/api-reference/runs/listRuns)

get <https://api.openai.com/v1/threads/{thread\_id}/runs>

Returns a list of runs belonging to a thread.

### Path parameters

[](#runs-listruns-thread_id)

thread_id

string

Required

The ID of the thread the run belongs to.

### Query parameters

[](#runs-listruns-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#runs-listruns-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#runs-listruns-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

[](#runs-listruns-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

### Returns

A list of [run](/docs/api-reference/runs/object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    from openai import OpenAI
    client = OpenAI()

    runs = client.beta.threads.runs.list(
      "thread_abc123"
    )
    print(runs)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    48
    49
    50
    51
    52
    53
    54
    55
    56
    57
    58
    59
    60
    61
    62
    63
    64
    65
    66
    67
    68
    69
    70
    {
      "object": "list",
      "data": [
        {
          "id": "run_abc123",
          "object": "thread.run",
          "created_at": 1699075072,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699075072,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699075073,
          "last_error": null,
          "model": "gpt-3.5-turbo",
          "instructions": null,
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "file_ids": [
            "file-abc123",
            "file-abc456"
          ],
          "metadata": {},
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          }
        },
        {
          "id": "run_abc456",
          "object": "thread.run",
          "created_at": 1699063290,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699063290,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699063291,
          "last_error": null,
          "model": "gpt-3.5-turbo",
          "instructions": null,
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "file_ids": [
            "file-abc123",
            "file-abc456"
          ],
          "metadata": {},
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          }
        }
      ],
      "first_id": "run_abc123",
      "last_id": "run_abc456",
      "has_more": false
    }

[

List run steps

Beta

---

](/docs/api-reference/runs/listRunSteps)

get <https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps>

Returns a list of run steps belonging to a run.

### Path parameters

[](#runs-listrunsteps-thread_id)

thread_id

string

Required

The ID of the thread the run and run steps belong to.

[](#runs-listrunsteps-run_id)

run_id

string

Required

The ID of the run the run steps belong to.

### Query parameters

[](#runs-listrunsteps-limit)

limit

integer

Optional

Defaults to 20

A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.

[](#runs-listrunsteps-order)

order

string

Optional

Defaults to desc

Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.

[](#runs-listrunsteps-after)

after

string

Optional

A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.

[](#runs-listrunsteps-before)

before

string

Optional

A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.

### Returns

A list of [run step](/docs/api-reference/runs/step-object) objects.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    run_steps = client.beta.threads.runs.steps.list(
        thread_id="thread_abc123",
        run_id="run_abc123"
    )
    print(run_steps)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    {
      "object": "list",
      "data": [
        {
          "id": "step_abc123",
          "object": "thread.run.step",
          "created_at": 1699063291,
          "run_id": "run_abc123",
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "type": "message_creation",
          "status": "completed",
          "cancelled_at": null,
          "completed_at": 1699063291,
          "expired_at": null,
          "failed_at": null,
          "last_error": null,
          "step_details": {
            "type": "message_creation",
            "message_creation": {
              "message_id": "msg_abc123"
            }
          },
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          }
        }
      ],
      "first_id": "step_abc123",
      "last_id": "step_abc456",
      "has_more": false
    }

[

Retrieve run

Beta

---

](/docs/api-reference/runs/getRun)

get <https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}>

Retrieves a run.

### Path parameters

[](#runs-getrun-thread_id)

thread_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

[](#runs-getrun-run_id)

run_id

string

Required

The ID of the run to retrieve.

### Returns

The [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    run = client.beta.threads.runs.retrieve(
      thread_id="thread_abc123",
      run_id="run_abc123"
    )
    print(run)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-3.5-turbo",
      "instructions": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ],
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

[

Retrieve run step

Beta

---

](/docs/api-reference/runs/getRunStep)

get <https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/steps/{step\_id}>

Retrieves a run step.

### Path parameters

[](#runs-getrunstep-thread_id)

thread_id

string

Required

The ID of the thread to which the run and run step belongs.

[](#runs-getrunstep-run_id)

run_id

string

Required

The ID of the run to which the run step belongs.

[](#runs-getrunstep-step_id)

step_id

string

Required

The ID of the run step to retrieve.

### Returns

The [run step](/docs/api-reference/runs/step-object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    from openai import OpenAI
    client = OpenAI()

    run_step = client.beta.threads.runs.steps.retrieve(
        thread_id="thread_abc123",
        run_id="run_abc123",
        step_id="step_abc123"
    )
    print(run_step)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

[

Modify run

Beta

---

](/docs/api-reference/runs/modifyRun)

post <https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}>

Modifies a run.

### Path parameters

[](#runs-modifyrun-thread_id)

thread_id

string

Required

The ID of the [thread](/docs/api-reference/threads) that was run.

[](#runs-modifyrun-run_id)

run_id

string

Required

The ID of the run to modify.

### Request body

[](#runs-modifyrun-metadata)

metadata

map

Optional

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    from openai import OpenAI
    client = OpenAI()

    run = client.beta.threads.runs.update(
      thread_id="thread_abc123",
      run_id="run_abc123",
      metadata={"user_id": "user_abc123"},
    )
    print(run)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075072,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699075072,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699075073,
      "last_error": null,
      "model": "gpt-3.5-turbo",
      "instructions": null,
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "file_ids": [
        "file-abc123",
        "file-abc456"
      ],
      "metadata": {
        "user_id": "user_abc123"
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

[

Submit tool outputs to run

Beta

---

](/docs/api-reference/runs/submitToolOutputs)

post <https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/submit\_tool\_outputs>

When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

### Path parameters

[](#runs-submittooloutputs-thread_id)

thread_id

string

Required

The ID of the [thread](/docs/api-reference/threads) to which this run belongs.

[](#runs-submittooloutputs-run_id)

run_id

string

Required

The ID of the run that requires the tool output submission.

### Request body

[](#runs-submittooloutputs-tool_outputs)

tool_outputs

array

Required

A list of tools for which the outputs are being submitted.

Hide properties

[](#runs-submittooloutputs-tool_outputs-tool_call_id)

tool_call_id

string

Optional

The ID of the tool call in the `required_action` object within the run object the output is being submitted for.

[](#runs-submittooloutputs-tool_outputs-output)

output

string

Optional

The output of the tool call to be submitted to continue the run.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    from openai import OpenAI
    client = OpenAI()

    run = client.beta.threads.runs.submit_tool_outputs(
      thread_id="thread_abc123",
      run_id="run_abc123",
      tool_outputs=[
        {
          "tool_call_id": "call_abc123",
          "output": "28C"
        }
      ]
    )
    print(run)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699075592,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "queued",
      "started_at": 1699075592,
      "expires_at": 1699076192,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4",
      "instructions": "You tell the weather.",
      "tools": [
        {
          "type": "function",
          "function": {
            "name": "get_weather",
            "description": "Determine weather in my location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and state e.g. San Francisco, CA"
                },
                "unit": {
                  "type": "string",
                  "enum": [
                    "c",
                    "f"
                  ]
                }
              },
              "required": [
                "location"
              ]
            }
          }
        }
      ],
      "file_ids": [],
      "metadata": {},
      "usage": null
    }

[

Cancel a run

Beta

---

](/docs/api-reference/runs/cancelRun)

post <https://api.openai.com/v1/threads/{thread\_id}/runs/{run\_id}/cancel>

Cancels a run that is `in_progress`.

### Path parameters

[](#runs-cancelrun-thread_id)

thread_id

string

Required

The ID of the thread to which this run belongs.

[](#runs-cancelrun-run_id)

run_id

string

Required

The ID of the run to cancel.

### Returns

The modified [run](/docs/api-reference/runs/object) object matching the specified ID.

Example request

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    from openai import OpenAI
    client = OpenAI()

    run = client.beta.threads.runs.cancel(
      thread_id="thread_abc123",
      run_id="run_abc123"
    )
    print(run)

Response

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1699076126,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "cancelling",
      "started_at": 1699076126,
      "expires_at": 1699076726,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": null,
      "last_error": null,
      "model": "gpt-4",
      "instructions": "You summarize books.",
      "tools": [
        {
          "type": "retrieval"
        }
      ],
      "file_ids": [],
      "metadata": {},
      "usage": null
    }

[

The run object

Beta

---

](/docs/api-reference/runs/object)

Represents an execution run on a [thread](/docs/api-reference/threads).

[](#runs/object-id)

id

string

The identifier, which can be referenced in API endpoints.

[](#runs/object-object)

object

string

The object type, which is always `thread.run`.

[](#runs/object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the run was created.

[](#runs/object-thread_id)

thread_id

string

The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run.

[](#runs/object-assistant_id)

assistant_id

string

The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run.

[](#runs/object-status)

status

string

The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, or `expired`.

[](#runs/object-required_action)

required_action

object or null

Details on the action required to continue the run. Will be `null` if no action is required.

Hide properties

[](#runs/object-required_action-type)

type

string

For now, this is always `submit_tool_outputs`.

[](#runs/object-required_action-submit_tool_outputs)

submit_tool_outputs

object

Details on the tool outputs needed for this run to continue.

Hide properties

[](#runs/object-required_action-submit_tool_outputs-tool_calls)

tool_calls

array

A list of the relevant tool calls.

Hide properties

[](#runs/object-required_action-submit_tool_outputs-tool_calls-id)

id

string

The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint.

[](#runs/object-required_action-submit_tool_outputs-tool_calls-type)

type

string

The type of tool call the output is required for. For now, this is always `function`.

[](#runs/object-required_action-submit_tool_outputs-tool_calls-function)

function

object

The function definition.

Hide properties

[](#runs/object-required_action-submit_tool_outputs-tool_calls-function-name)

name

string

The name of the function.

[](#runs/object-required_action-submit_tool_outputs-tool_calls-function-arguments)

arguments

string

The arguments that the model expects you to pass to the function.

[](#runs/object-last_error)

last_error

object or null

The last error associated with this run. Will be `null` if there are no errors.

Hide properties

[](#runs/object-last_error-code)

code

string

One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.

[](#runs/object-last_error-message)

message

string

A human-readable description of the error.

[](#runs/object-expires_at)

expires_at

integer

The Unix timestamp (in seconds) for when the run will expire.

[](#runs/object-started_at)

started_at

integer or null

The Unix timestamp (in seconds) for when the run was started.

[](#runs/object-cancelled_at)

cancelled_at

integer or null

The Unix timestamp (in seconds) for when the run was cancelled.

[](#runs/object-failed_at)

failed_at

integer or null

The Unix timestamp (in seconds) for when the run failed.

[](#runs/object-completed_at)

completed_at

integer or null

The Unix timestamp (in seconds) for when the run was completed.

[](#runs/object-model)

model

string

The model that the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-instructions)

instructions

string

The instructions that the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-tools)

tools

array

The list of tools that the [assistant](/docs/api-reference/assistants) used for this run.

Hide possible types

Code interpreter tool

object

Hide properties

[](#runs/object-tools-code-interpreter-tool-type)

type

string

The type of tool being defined: `code_interpreter`

Retrieval tool

object

Hide properties

[](#runs/object-tools-retrieval-tool-type)

type

string

The type of tool being defined: `retrieval`

Function tool

object

Hide properties

[](#runs/object-tools-function-tool-type)

type

string

The type of tool being defined: `function`

[](#runs/object-tools-function-tool-function)

function

object

Hide properties

[](#runs/object-tools-function-tool-function-description)

description

string

A description of what the function does, used by the model to choose when and how to call the function.

[](#runs/object-tools-function-tool-function-name)

name

string

The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.

[](#runs/object-tools-function-tool-function-parameters)

parameters

object

The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/text-generation/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.

Omitting `parameters` defines a function with an empty parameter list.

[](#runs/object-file_ids)

file_ids

array

The list of [File](/docs/api-reference/files) IDs the [assistant](/docs/api-reference/assistants) used for this run.

[](#runs/object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

[](#runs/object-usage)

usage

object or null

Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).

Hide properties

[](#runs/object-usage-completion_tokens)

completion_tokens

integer

Number of completion tokens used over the course of the run.

[](#runs/object-usage-prompt_tokens)

prompt_tokens

integer

Number of prompt tokens used over the course of the run.

[](#runs/object-usage-total_tokens)

total_tokens

integer

Total number of tokens used (prompt + completion).

The run object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    {
      "id": "run_abc123",
      "object": "thread.run",
      "created_at": 1698107661,
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "status": "completed",
      "started_at": 1699073476,
      "expires_at": null,
      "cancelled_at": null,
      "failed_at": null,
      "completed_at": 1699073498,
      "last_error": null,
      "model": "gpt-4",
      "instructions": null,
      "tools": [{"type": "retrieval"}, {"type": "code_interpreter"}],
      "file_ids": [],
      "metadata": {},
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

[

The run step object

Beta

---

](/docs/api-reference/runs/step-object)

Represents a step in execution of a run.

[](#runs/step-object-id)

id

string

The identifier of the run step, which can be referenced in API endpoints.

[](#runs/step-object-object)

object

string

The object type, which is always `thread.run.step`.

[](#runs/step-object-created_at)

created_at

integer

The Unix timestamp (in seconds) for when the run step was created.

[](#runs/step-object-assistant_id)

assistant_id

string

The ID of the [assistant](/docs/api-reference/assistants) associated with the run step.

[](#runs/step-object-thread_id)

thread_id

string

The ID of the [thread](/docs/api-reference/threads) that was run.

[](#runs/step-object-run_id)

run_id

string

The ID of the [run](/docs/api-reference/runs) that this run step is a part of.

[](#runs/step-object-type)

type

string

The type of run step, which can be either `message_creation` or `tool_calls`.

[](#runs/step-object-status)

status

string

The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.

[](#runs/step-object-step_details)

step_details

object

The details of the run step.

Hide possible types

Message creation

object

Details of the message creation by the run step.

Hide properties

[](#runs/step-object-step_details-message-creation-type)

type

string

Always `message_creation`.

[](#runs/step-object-step_details-message-creation-message_creation)

message_creation

object

Hide properties

[](#runs/step-object-step_details-message-creation-message_creation-message_id)

message_id

string

The ID of the message that was created by this run step.

Tool calls

object

Details of the tool call.

Hide properties

[](#runs/step-object-step_details-tool-calls-type)

type

string

Always `tool_calls`.

[](#runs/step-object-step_details-tool-calls-tool_calls)

tool_calls

array

An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `retrieval`, or `function`.

Hide possible types

Code interpreter tool call

object

Details of the Code Interpreter tool call the run step was involved in.

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-id)

id

string

The ID of the tool call.

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-type)

type

string

The type of tool call. This is always going to be `code_interpreter` for this type of tool call.

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter)

code_interpreter

object

The Code Interpreter tool call definition.

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-input)

input

string

The input to the Code Interpreter tool call.

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-outputs)

outputs

array

The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.

Hide possible types

Code interpreter log output

object

Text output from the Code Interpreter tool call as part of a run step.

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-outputs-code-interpreter-log-output-type)

type

string

Always `logs`.

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-outputs-code-interpreter-log-output-logs)

logs

string

The text output from the Code Interpreter tool call.

Code interpreter image output

object

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-outputs-code-interpreter-image-output-type)

type

string

Always `image`.

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-outputs-code-interpreter-image-output-image)

image

object

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-code-interpreter-tool-call-code_interpreter-outputs-code-interpreter-image-output-image-file_id)

file_id

string

The [file](/docs/api-reference/files) ID of the image.

Retrieval tool call

object

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-retrieval-tool-call-id)

id

string

The ID of the tool call object.

[](#runs/step-object-step_details-tool-calls-tool_calls-retrieval-tool-call-type)

type

string

The type of tool call. This is always going to be `retrieval` for this type of tool call.

[](#runs/step-object-step_details-tool-calls-tool_calls-retrieval-tool-call-retrieval)

retrieval

map

For now, this is always going to be an empty object.

Function tool call

object

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-function-tool-call-id)

id

string

The ID of the tool call object.

[](#runs/step-object-step_details-tool-calls-tool_calls-function-tool-call-type)

type

string

The type of tool call. This is always going to be `function` for this type of tool call.

[](#runs/step-object-step_details-tool-calls-tool_calls-function-tool-call-function)

function

object

The definition of the function that was called.

Hide properties

[](#runs/step-object-step_details-tool-calls-tool_calls-function-tool-call-function-name)

name

string

The name of the function.

[](#runs/step-object-step_details-tool-calls-tool_calls-function-tool-call-function-arguments)

arguments

string

The arguments passed to the function.

[](#runs/step-object-step_details-tool-calls-tool_calls-function-tool-call-function-output)

output

string or null

The output of the function. This will be `null` if the outputs have not been [submitted](/docs/api-reference/runs/submitToolOutputs) yet.

[](#runs/step-object-last_error)

last_error

object or null

The last error associated with this run step. Will be `null` if there are no errors.

Hide properties

[](#runs/step-object-last_error-code)

code

string

One of `server_error` or `rate_limit_exceeded`.

[](#runs/step-object-last_error-message)

message

string

A human-readable description of the error.

[](#runs/step-object-expired_at)

expired_at

integer or null

The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.

[](#runs/step-object-cancelled_at)

cancelled_at

integer or null

The Unix timestamp (in seconds) for when the run step was cancelled.

[](#runs/step-object-failed_at)

failed_at

integer or null

The Unix timestamp (in seconds) for when the run step failed.

[](#runs/step-object-completed_at)

completed_at

integer or null

The Unix timestamp (in seconds) for when the run step completed.

[](#runs/step-object-metadata)

metadata

map

Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.

[](#runs/step-object-usage)

usage

object or null

Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`.

Hide properties

[](#runs/step-object-usage-completion_tokens)

completion_tokens

integer

Number of completion tokens used over the course of the run step.

[](#runs/step-object-usage-prompt_tokens)

prompt_tokens

integer

Number of prompt tokens used over the course of the run step.

[](#runs/step-object-usage-total_tokens)

total_tokens

integer

Total number of tokens used (prompt + completion).

The run step object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    {
      "id": "step_abc123",
      "object": "thread.run.step",
      "created_at": 1699063291,
      "run_id": "run_abc123",
      "assistant_id": "asst_abc123",
      "thread_id": "thread_abc123",
      "type": "message_creation",
      "status": "completed",
      "cancelled_at": null,
      "completed_at": 1699063291,
      "expired_at": null,
      "failed_at": null,
      "last_error": null,
      "step_details": {
        "type": "message_creation",
        "message_creation": {
          "message_id": "msg_abc123"
        }
      },
      "usage": {
        "prompt_tokens": 123,
        "completion_tokens": 456,
        "total_tokens": 579
      }
    }

[

Completions

Legacy

---

](/docs/api-reference/completions)

Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation/text-generation-models) to leverage our best and newest models.

[

Create completion

Legacy

---

](/docs/api-reference/completions/create)

post <https://api.openai.com/v1/completions>

Creates a completion for the provided prompt and parameters.

### Request body

[](#completions-create-model)

model

string

Required

ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.

[](#completions-create-prompt)

prompt

string or array

Required

The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.

[](#completions-create-best_of)

best_of

integer or null

Optional

Defaults to 1

Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

[](#completions-create-echo)

echo

boolean or null

Optional

Defaults to false

Echo back the prompt in addition to the completion

[](#completions-create-frequency_penalty)

frequency_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

[](#completions-create-logit_bias)

logit_bias

map

Optional

Defaults to null

Modify the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.

[](#completions-create-logprobs)

logprobs

integer or null

Optional

Defaults to null

Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

The maximum value for `logprobs` is 5.

[](#completions-create-max_tokens)

max_tokens

integer or null

Optional

Defaults to 16

The maximum number of [tokens](/tokenizer) that can be generated in the completion.

The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.

[](#completions-create-n)

n

integer or null

Optional

Defaults to 1

How many completions to generate for each prompt.

**Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.

[](#completions-create-presence_penalty)

presence_penalty

number or null

Optional

Defaults to 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

[See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

[](#completions-create-seed)

seed

integer or null

Optional

If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.

[](#completions-create-stop)

stop

string / array / null

Optional

Defaults to null

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

[](#completions-create-stream)

stream

boolean or null

Optional

Defaults to false

Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

[](#completions-create-suffix)

suffix

string or null

Optional

Defaults to null

The suffix that comes after a completion of inserted text.

[](#completions-create-temperature)

temperature

number or null

Optional

Defaults to 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

We generally recommend altering this or `top_p` but not both.

[](#completions-create-top_p)

top_p

number or null

Optional

Defaults to 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

[](#completions-create-user)

user

string

Optional

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

### Returns

Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.

No streaming‍ Streaming‍

Example request

gpt-3.5-turbo-instruct

gpt-3.5-turbo-instruct-0914 babbage-002 gpt-3.5-turbo-instruct davinci-002

python

Select library curl python node.js

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    from openai import OpenAI
    client = OpenAI()

    client.completions.create(
      model="gpt-3.5-turbo-instruct",
      prompt="Say this is a test",
      max_tokens=7,
      temperature=0
    )

Response

gpt-3.5-turbo-instruct

gpt-3.5-turbo-instruct-0914 babbage-002 gpt-3.5-turbo-instruct davinci-002

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    {
      "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
      "object": "text_completion",
      "created": 1589478378,
      "model": "gpt-3.5-turbo-instruct",
      "system_fingerprint": "fp_44709d6fcb",
      "choices": [
        {
          "text": "\n\nThis is indeed a test",
          "index": 0,
          "logprobs": null,
          "finish_reason": "length"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
      }
    }

[

The completion object

Legacy

---

](/docs/api-reference/completions/object)

Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).

[](#completions/object-id)

id

string

A unique identifier for the completion.

[](#completions/object-choices)

choices

array

The list of completion choices the model generated for the input prompt.

Hide properties

[](#completions/object-choices-finish_reason)

finish_reason

string

The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, or `content_filter` if content was omitted due to a flag from our content filters.

[](#completions/object-choices-index)

index

integer

[](#completions/object-choices-logprobs)

logprobs

object or null

Hide properties

[](#completions/object-choices-logprobs-text_offset)

text_offset

array

[](#completions/object-choices-logprobs-token_logprobs)

token_logprobs

array

[](#completions/object-choices-logprobs-tokens)

tokens

array

[](#completions/object-choices-logprobs-top_logprobs)

top_logprobs

array

Show properties

[](#completions/object-choices-text)

text

string

[](#completions/object-created)

created

integer

The Unix timestamp (in seconds) of when the completion was created.

[](#completions/object-model)

model

string

The model used for completion.

[](#completions/object-system_fingerprint)

system_fingerprint

string

This fingerprint represents the backend configuration that the model runs with.

Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.

[](#completions/object-object)

object

string

The object type, which is always "text_completion"

[](#completions/object-usage)

usage

object

Usage statistics for the completion request.

Hide properties

[](#completions/object-usage-completion_tokens)

completion_tokens

integer

Number of tokens in the generated completion.

[](#completions/object-usage-prompt_tokens)

prompt_tokens

integer

Number of tokens in the prompt.

[](#completions/object-usage-total_tokens)

total_tokens

integer

Total number of tokens used in the request (prompt + completion).

The completion object

Copy‍

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    {
      "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
      "object": "text_completion",
      "created": 1589478378,
      "model": "gpt-3.5-turbo",
      "choices": [
        {
          "text": "\n\nThis is indeed a test",
          "index": 0,
          "logprobs": null,
          "finish_reason": "length"
        }
      ],
      "usage": {
        "prompt_tokens": 5,
        "completion_tokens": 7,
        "total_tokens": 12
      }
    }
